---
layout: blog
authors: [ivagljiva, FlorianTrigodet]
title: Metabin refinement and population genetics using human tongue metagenomes
excerpt: "A multi-purpose tutorial based on human oral microbiome data"
date: 2025-03-05
tags: [metagenomics, binning, population genetics, hands-on, beginner]
comments: true
---

Real world datasets are complicated, and it can be difficult to accurately capture this in tutorials due to time and space constraints. The infamous [Infant Gut Tutorial](https://merenlab.org/tutorials/infant-gut/) covers the basics of both binning and population genetics on an extremely simple dataset, which is great for learning but the process and results are not necessarily representative of what one would actually end up doing/seeing in a large-scale 'omics study. Take binning, for example -- if you have dozens of large co-assemblies in your dataset, you won't have the time to do manual binning (and even if you wanted to, chances are that your dataset would be too large to visualize in the anvi'o interactive interface). And microbial communities containing hundreds of populations rarely show perfectly clean, easy-to-bin patterns of sequence composition and differential coverage. As for population genetics, our existing tutorial shows you how to do the thing, but leaves out some context for the question and important parameter decisions along the way.

With that in mind, we created this tutorial to show a more realistic example of how to work on both metagenomic binning and population genetics in anvi'o, using real-world data from the human oral microbiome as generated in the paper ["Functional and genetic markers of niche partitioning among enigmatic members of the human oral microbiome"](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02195-w) by Shaiber et al (2020). Our goal is to show you the following:

- How to run a read recruitment workflow from many samples to a co-assembly, to generate differential coverage data for binning as well as variant data for population genetics
- How to manually refine a 'metabin' that was automatically generated by CONCOCT and encompasses several microbial populations into a few smaller yet high-quality bins
- How to set some key parameters in a population genetics analysis that answers a (somewhat) realistic research question

Of course, we are still constrained a little bit by the time and computational resources allowed by a typical tutorial session. We will be working with a smallish co-assembly that is entirely visualizable in the anvi'o interactive interface (unlike many real-world datasets). And it is unlikely that we will actually run the read recruitment workflow in a tutorial setting (but we will give you all the tools to do so in case you want to try it at home).

Without further ado, let's begin :)

## Our dataset and questions

We are taking advantage of the [publicly-available data](https://merenlab.org/data/#niche-partitioning-in-the-human-oral-cavity) from Shaiber et al 2020. This study described a time-series of tongue and plague metagenomes taken from several human individuals, most of which were paired in male-female couples. This sampling strategy is particularly effective for metagenomic binning for the following reasons. First, having multiple samples from a single individual enabled the authors to do co-assembly, which effectively increases the coverage and likelihood of catching low-abundance populations (at the cost of increasing the overall complexity, which can break assembly algorithms). Second, we know that similar populations likely occur across different individuals and it therefore makes sense to map multiple individuals to a given co-assembly to leverage more differential coverage signals -- this was not the strategy used in the Shaiber et al 2020 paper, but it will work quite well for our purposes today.

Here are the questions we want to answer using this dataset:

1. What microbial populations can we recover high-quality metagenome-assembled genomes (MAGs) for by refining 'metabins'?
2. Do the individuals in a couple share similar populations in their oral microbiomes? To put it another way -- can the population variants specific to a given individual help us distinguish between the couples?

In order to answer these questions at a smaller scale, we will be using a subset of the data from the 2020 study - a co-assembly of 5 tongue samples from the time-series of a single individual (the sample named `T-B-M` in the original paper), plus 20 tongue metagenomes to recruit reads from. These include the 5 samples used to make the co-assembly and 5 each from three other individuals: `T-A-F`, `T-A-M`, and `T-B-F`.

For the purposes of this tutorial, we will use the co-assembly that was already generated by the study authors. We will start our binning journey from the results of the automatic binning tool [CONCOCT](https://github.com/BinPro/CONCOCT) ([Alneberg et al 2014](https://www.nature.com/articles/nmeth.3103)) that was already run on the co-assembly. 

In fact, CONCOCT was run twice -- once by specifying `-c 10` to force the tool to create exactly 10 'metabins' (each containing multiple microbial populations), and once without enforcing a number of bins (in which case the tool would try to group sequences from exactly one population in each bin). The 'metabin' strategy is extremely useful for partitioning your large metagenomic datasets into manageable chunks that can be manually refined, and is described elsewhere in [a blog post by Tom and Meren](https://anvio.org/blog/constrained-binning/).

## The mapping workflow

If all we wanted to do was bin refinement, a read recruitment step wouldn't really be necessary here. After all, the automatic binning results were already generated using existing read recruitment results whereby the 5 time-series samples were mapped against their co-assembly. So we could have just taken the existing, publicly-available contigs and profile databases from [this Figshare](https://figshare.com/articles/dataset/Anvi_o_profiles_per_individual/12217802) and done our bin refinement on that. 

But we want more than that. To answer question (2), we also want to see how the tongue-associated populations from the individual `T-B-M` differ from the tongue-associated populations in the three other individuals (which means we need mapping information from 15 additional samples). And if we are going to map additional samples to the co-assembly anyway, might as well use them to help guide our bin refinement process.

This is probably not a step that you want to run on a laptop. We did it on our high-performance computing cluster (HPC), using the {% include WORKFLOW name="metagenomics" text="snakemake workflow for metagenomics" %} implemented in {% include PROGRAM name="anvi-run-workflow" text="anvi-run-workflow" %}. We will show you how we set this workflow up, but there is no need for you to run it yourself - you will be able to download the output of the workflow that is required for the rest of the tutorial in the next section.

<details markdown="1"><summary>Show/Hide You want to run the mapping workflow yourself? Here is how to get the short read data. </summary>

To get the metagenome samples, open the [SRA Run Selector for the BioProject PRJNA625082](https://www.ncbi.nlm.nih.gov/Traces/study/?query_key=2&WebEnv=MCID_67c08dce0e84b53f0ea4df2a&f=env_medium_sam_ss%3An&o=acc_s%3Aa) in your favorite web browser. In the filters on the left side, filter for 'host_tissue_sampled' = 'Tongue' and 'Assay_Type' = 'WGS' to get all the tongue samples. Then downloaded the metadata table as a CSV. You can then select only the time-series samples from our 4 individuals of interest by running the following code on the metadata table in your terminal:

```
# keep only accession and sample name
cut -d ',' -f 1,45 Oral_Microbiome_SraRunTable.csv | tr ',' '\t' > oral_samples.txt
# search for sample names of interest and extract to a new file
for n in T_B_M T_B_F T_A_F T_A_M; do \
  grep $n oral_samples.txt >> oral_samps_to_download.txt ; \
done
# extract only the accession for the samples of interest
cut -f 1 oral_samps_to_download.txt > SRA_accession_list.txt
```

This creates a file of SRA accession numbers that becomes the input to the {% include WORKFLOW name="sra-download" text="SRA download workflow" %}. You should put that `SRA_accession_list.txt` file wherever you want to download those samples (for instance, on your HPC), and then get a default {% include ARTIFACT name="workflow-config" text="config file" %} for the workflow:

```
anvi-run-workflow -w sra_download --get-default-config download.json
```

Feel free to open that config and change the parameters (for instance, number of threads) for each rule according to the computational resources available to you.

When you are ready to download the samples, running the workflow is as simple as this:

```
anvi-run-workflow -w sra_download -c download.json
```

If you are running on a cluster, you may want to use the `--additional-params` (or `-A`) flag to pass cluster-specific scheduler commands and resource limits to snakemake using flags such as `--cluster`, `--resources`, `--jobs`, etc.

Once the workflow is done, you should have a folder of FASTQ files for 20 metagenome samples. And then you'll be ready to run the mapping workflow!

</details>

So, how did we run the {% include WORKFLOW name="metagenomics" text="mapping workflow" %}?

First, we got our reference metagenome co-assembly for individual T-B-M by downloading the corresponding {% include ARTIFACT name="contigs-db" text="contigs" %} and {% include ARTIFACT name="profile-db" text="profile" %} database from [this Figshare link](https://figshare.com/articles/dataset/Anvi_o_profiles_per_individual/12217802). Then, we extracted the FASTA file of the contigs, as well as both existing CONCOCT {% include ARTIFACT name="collection" text="collections" %} that were already stored in the profile database:

```
# extract le data
tar -xvf T-B-M.tar.gz

# update the dbs to match your current anvi'o version
anvi-migrate --migrate-safe T-B-M/*.db

# get our reference FASTA file
anvi-export-contigs -c T-B-M/CONTIGS.db -o T_B_M-contigs.fa

# export the metabin collection
anvi-export-collection -p T-B-M/PROFILE.db -C CONCOCT_c10 -O CONCOCT_c10

# export the standard CONCOCT collection
anvi-export-collection -p T-B-M/PROFILE.db -C CONCOCT -O CONCOCT
```

We will use the FASTA file of the co-assembly contigs as the reference in our mapping workflow. The mapping workflow will create a new contigs database out of this FASTA file, and associate the mapping data to that new contigs database via a new (merged) profile database containing the mapping info from all 20 of our samples. Because we'll get a fresh profile database that won't have any of the existing collection information in it, we will need to import the collection data (using the collection files we just exported) so that we can do our bin refinement from there. Luckily, because we exported our reference FASTA directly from the contigs database, the split names in the exported {% include ARTIFACT name="collection-txt" text="collection files" %} will match to the names in the new contigs database. But we are getting ahead of ourselves. First we actually have to run the workflow.

On our HPC, we navigated to the folder where we downloaded the 20 metagenome samples that we want to map against this co-assembly. We created a {% include ARTIFACT name="samples-txt" text="samples-txt" %} file that describes the paths to each of the samples (you can see the format [here](https://anvio.org/help/main/artifacts/samples-txt/)). Then we generated a {% include ARTIFACT name="fasta-txt" text="fasta-txt" %} file with the path to our reference co-assembly FASTA, and we got a default {% include ARTIFACT name="workflow-config" text="config file" %} for the metagenomics workflow:

```
echo -e "name\tpath\nT_B_M\tT_B_M-contigs.fa" > fasta.txt
anvi-run-workflow -w metagenomics --get-default-config map.json
```

After modifying the config file a bit to turn on 'reference mode', turn on references mode, turn off unnecessary rules (like functional annotation),, and increase the number of threads for each rule as much as our cluster could handle, we did a dry run (using the `-n` dry run flag and `-q` quiet flag passed directly to snakemake using `-A` or `--additional-params`) to see what the workflow would actually run:
```
anvi-run-workflow -w metagenomics -c map.json -A -n -q
```

And it showed us the following list of jobs:
```
job                                  count
---------------------------------  -------
annotate_contigs_database                1
anvi_gen_contigs_database                1
anvi_init_bam                           20
anvi_merge                               1
anvi_profile                            20
anvi_run_hmms                            1
anvi_run_scg_taxonomy                    1
bowtie                                  20
bowtie_build                             1
gen_qc_report                            1
gzip_fastqs                             40
import_percent_of_reads_mapped          20
iu_filter_quality_minoche               20
iu_gen_configs                           1
metagenomics_workflow_target_rule        1
samtools_view                           20
total                                  169
```

Everything looked okay in the dry run. We have 20 samples, so it makes sense that we are doing all the sample-specific jobs 20 times (the only exception, `gzip_fastqs`, works individually on R1 and R2 files, so it runs twice per samples).

We very confidently started the workflow using the command:

```
anvi-run-workflow -w metagenomics -c map.json
```

And after it finished successfully, we took the resulting contigs database and merged profile database, and we imported the original collections of CONCOCT bins that we extracted previously:

```
anvi-import-collection -p PROFILE.db -C CONCOCT_c10 CONCOCT_c10.txt -c T_B_M-contigs.db
anvi-import-collection -c T_B_M-contigs.db -p PROFILE.db -C CONCOCT CONCOCT.txt
```

These are the databases that were put into the datapack for this tutorial, which you can download in the next section.

## Refining CONCOCT metabins

First, let's download the tutorial datapack. Just so you know, the archived databack is about half a gigabyte in size, and once unpacked it will take up ~1.6Gb of space on your computer. If you are okay with that, here are the download commands:

```
wget https://figshare.com/ndownloader/files/52819088 -O BINNING_POPGEN_TUTORIAL.tar.gz
tar -xvf BINNING_POPGEN_TUTORIAL.tar.gz && cd BINNING_POPGEN_TUTORIAL/
```

You should now be inside the datapack directory on your terminal. The directory should contain 3 databases -- the {% include ARTIFACT name="contigs-db" text="contigs database" %} containing the co-assembly of the 5 time-series tongue metagenomes from one individual (`T-B-M`), the {% include ARTIFACT name="profile-db" text="profile database" %} containing the mapping data from 20 tongue metagenome samples (from the same `T-B-M` individual as well as three others), and an auxiliary database with lots of extra info related to the mapping (which we will use later).

### An initial look at the co-assembly

Let's take a look at what we have in the database.

```
anvi-display-contigs-stats T_B_M-contigs.db
```

A little interactive window should pop up in your browser, filled with useful tables of statistics about the co-assembly. At the top you will see a bar chart of the number of annotations to each single-copy core gene (SCGs; which can be annotated by running {% include PROGRAM name="anvi-run-hmms" text="anvi-run-hmms" %}) in the assembly contigs. Here is the chart for the `Bacteria_71` set of bacterial SCGs:

{% include IMAGE width=40 path="/images/binning-popgen-oral-microbiome/T-B-M_hmm_hits_barchart.png" caption="A bar chart of hits to bacterial SCGs in the T-B-M co-assembly" %}

Since we expect that each microbial population should have one copy of each of these SCGs, it looks like we have at least 20 bacterial populations in this co-assmbly (and at most 35). In fact, the most common number of hits to a given bacterial SCG is 25, which is exactly the number of bacterial genomes that anvi'o predicted this assembly to have:

{% include IMAGE width=40 path="/images/binning-popgen-oral-microbiome/T-B-M_num_genomes.png" caption="Predicted number of populations in the T-B-M co-assembly, based on SCG counts" %}

If you want to learn more about how anvi'o estimates the number of genomes, you can click the little `[?]` link in the interactive interface, or just click on [this conveniently-placed link](https://anvio.org/help/main/programs/anvi-display-contigs-stats/#how-do-we-predict-the-number-of-genomes) to the same documentation.

Anyway, we expect to find at least **25 bacterial populations** in this co-assembly. We're going to do our best to bin at least some of these populations.

We will be refining metabins that were automatically binned by CONCOCT. Let's check which {% include ARTIFACT name="collection" text="collections" %} we have available for this co-assembly. Collections of bins are stored in the profile database, so we pass that database as a parameter to {% include PROGRAM name="anvi-show-collections-and-bins" text="anvi-show-collections-and-bins" %}:

```
anvi-show-collections-and-bins -p PROFILE.db
```

You should see two collections. One of them is just called `CONCOCT` and it contains over 50 bins:

```
Collection: "CONCOCT"
===============================================
Collection ID ................................: CONCOCT
Number of bins ...............................: 58
Number of splits described ...................: 12,499
Number of contigs described ..................: 12,173
```

These are the binning results from a standard run of CONCOCT, whereby the program did its best to split each individual microbial population into its own bin. As you can see, the number of bins is much larger than the expected number of microbial populations based on single-copy core genes. It is always possible (and perhaps even likely) that we are missing some SCG annotations due to incomplete coverage of less abundant populations. However, it is also possible (and perhaps even very likely) that CONCOCT fragmented some of these population genomes across multiple bins. Which is one reason that we like to use the metabin approach described in [this blog post](https://anvio.org/blog/constrained-binning/) - if you tell CONCOCT to make just a few bins (much less than the number of expected populations), then it is less likely to split sequences from the same population across different bins.

Happily, the second collection in the profile database, `CONCOCT_c10`, is the metabin collection. Shaiber et al. created this collection by running CONCOCT with the `-c 10` parameter, to request 10 bins:

```
Collection: "CONCOCT_c10"
===============================================
Collection ID ................................: CONCOCT_c10
Number of bins ...............................: 10
Number of splits described ...................: 12,499
Number of contigs described ..................: 12,173
Bin names ....................................: Bin_1, Bin_10, Bin_2, Bin_3, Bin_4, Bin_5, Bin_6, Bin_7, Bin_8, Bin_9
```

This is the collection we are going to work on in just a moment.

First, let's just take a look at the co-assembly and its mapping data.

```
anvi-interactive -c T_B_M-contigs.db -p PROFILE.db \
    --title "T-B-M co-assembly"
```

{% include IMAGE width=40 path="/images/binning-popgen-oral-microbiome/T-B-M_coassembly_plain.png" caption="The T-B-M co-assembly in the interactive interface." %}


The profile database comes with pre-loaded settings to make the visualization a bit more digestible. The sample layers are colored according to which individual they come from - in particular, the 5 `T-B-M` samples that were used to make the co-assembly are in dark green. We can see coverage patterns in the samples from the other individuals that were mapped to this co-assembly -- the other individuals' tongue microbiomes include similar populations to those in `T-B-M`'s -- which is good news for us because it means we can use the mapping data from the other samples to help guide our bin refinement.

If you check the 'Items order' label at the top, you will see that the contigs (technically, their [splits](https://anvio.org/vocabulary/#split)) are organized according to their shared sequence composition (tetranucleotide frequency) and differential coverage patterns across all 20 samples. The inner dendrogram displays this organization, and we often use this dendrogram to select which contigs to put into a bin -- because we expect that sequences originating from the same genome should have roughly the same composition and follow similar differential coverage patterns.

Just out of curiousity, let's take a look at how the standard CONCOCT bins group the contigs from the co-assembly. You can _either_ load the bin collection `CONCOCT` from the 'Bins' panel in the interface, or close and re-open the interface with `--collection-autoload` in the command:

```
anvi-interactive -c T_B_M-contigs.db -p PROFILE.db \
    --title "T-B-M co-assembly (CONCOCT collection)" \
    --collection-autoload CONCOCT
```

{% include IMAGE width=40 path="/images/binning-popgen-oral-microbiome/T-B-M_coassembly_concoct.png" caption="The regular CONCOCT bins" %}

You can see a lot of mixing between the different bins. There are some sections of the figure where a clade on the inner dendrogram has been sorted into a single bin (such as Bin 2, Bin 10, and Bin 11), but for the most part, the bins are quite fragmented. This is exactly what we wanted to avoid by using the metabin technique.

What do the metabins look like? Again, you can load the collection from the interface, or re-start the interface with a new collection name to load:

```
anvi-interactive -c T_B_M-contigs.db -p PROFILE.db \
    --title "T-B-M co-assembly (CONCOCT_c10 collection)" \
    --collection-autoload CONCOCT_c10
```

{% include IMAGE width=40 path="/images/binning-popgen-oral-microbiome/T-B-M_coassembly_concoct_c10.png" caption="The 10 CONCOCT metabins" %}

It is a little bit better. Now multiple bacterial populations have been purposefully combined into just a few metabins, and we can see a bit less mixing; ie, the binning follows the dendrogram structure better. And in general, the mixing is not as chaotic -- many clades of the inner dendrogram are sorted into just two bins. We should be able to work with this output to refine a metabin into some high-quality MAGs.

{:.notice}
**Why so much mixing? Is CONCOCT doing a really bad job?**
Maybe. After all, automatic binning of complex metagenomes [is an extremely difficult task and algorithmic heuristics won't always give us an answer we expect](https://merenlab.org/2020/01/02/visualizing-metagenomic-bins/). But maybe not. It is important to remember that CONCOCT was given only a fraction of the information shown here to base its binning decisions on. It only used differential coverage signal from the 5 dark green samples from T-B-M -- the samples used to make the co-assembly. Here, we are showing mapping information from 15 extra samples from 3 different individuals, and while it seems clear that those individuals harbor _similar_ populations, there is likely still some variation like large-scale insertions and deletions or hyper-variable regions that could confuse the differential coverage signals. So give CONCOCT a break -- it is trying its best to live up to our unrealistic expectations. :P

### Refining Bin 3

We want to refine a metabin and split it into its component populations. But which metabin should we work on? If you take a look in the 'Bins' panel on the interactive interface, you should see the overall completeness and redundancy estimates for each one:

{% include IMAGE width=40 path="/images/binning-popgen-oral-microbiome/T-B-M_coassembly_c10_bins.png" caption="Completion and redundancy of the metabins" %}

As expected, they have a lot of redundancy because each bin contains several microbial populations. The only potential exception is Bin 2, which clearly stands out as one of the only bins that cohesively groups several consecutive clades in the inner dendrogram and seems to represent a single population based on the coverage patterns (though the size of the bin is a bit large for most microbial genomes). So we would like to focus on refining one of the other bins.

Somewhat arbitrarily, we selected the second-largest bin, Bin 3, to refine for this tutorial. Based on its redundancy score, we should be able to obtain at least 4-5 bins out of this metabin (potentially more if the populations are incomplete).

Here is the command to refine Bin 3. It will open the interactive interface again, but this time _only_ showing the contigs (technically, their [splits](https://anvio.org/vocabulary/#split)) belonging to Bin 3.

```
anvi-refine -c T_B_M-contigs.db -p PROFILE.db -C CONCOCT_c10 -b Bin_3
```

Here is what Bin 3 looks like in the interface:

{% include IMAGE width=40 path="/images/binning-popgen-oral-microbiome/T-B-M_refine_bin3.png" caption="Refining metabin 'Bin 3' in the interface's 'refine mode'." %}

Now we can use the dendrogram organization, the differential coverage patterns, and the SCG-based completion/redundancy/taxonomy estimates to identify the subsets of this metabin that represent individual population genomes. Give it a try for yourself, and once you are ready, click the _Show/Hide_ box to see if your results match ours.

<details markdown="1"><summary>Show/Hide Our Bin 3 refinement results. </summary>

We focused on the major patterns and ended up with 7 bins in our refined collection. We could have binned much more, but when we tried that, most of the resulting bins were so small/incomplete that they wouldn't have been useful. Here is what our collection looks like in the 'refine mode' interface:

{% include IMAGE width=40 path="/images/binning-popgen-oral-microbiome/Bin_3_refined.png" caption="The 7 bins resulting from our refinement." %}

And here are the bin statistics from the 'Bins' panel on the side:

{% include IMAGE width=40 path="/images/binning-popgen-oral-microbiome/Bin_3_refined_completion.png" caption="Statistics of the 7 refined bins from metabin 'Bin 3'." %}

We named the bins according to the SCG taxonomy estimates. There are several _Prevotella_ populations, but only 1 (_Prevotella sp013333285_) has a large enough and complete enough bin to be useful. There were also two decent bins for _Nanosynococcus_ species -- also known as TM7, these populations were the center of attention in the Shaiber et al. paper, so it is unsurprising that we found them here.

</details>

Make sure to hit the button called 'Store refined bins in database' in the 'Bins' panel to save your work once you are done refining. Please note that this will _overwrite_ your existing larger collection (in our case, this is the `CONCOCT_c10` collection), replacing the original metabin (`Bin_3`) with the set of smaller bins you curated.

Congratulations! You just refined a metabin. :)

If you want to see how your bin looks in the context of the larger co-assembly, you can do that by going back to the regular interactive interface, using the following command to automatically open the (now partially-refined) `CONCOCT_c10` collection.

```
anvi-interactive -c T_B_M-contigs.db -p PROFILE.db \
    --title "T-B-M co-assembly (CONCOCT_c10 collection)" \
    --collection-autoload CONCOCT_c10
```

<details markdown="1"><summary>Show/Hide Our Bin 3 refinement results, in the co-assembly. </summary>

If you want to load our collection of refined bins to view them in the larger context, you can run the following:

```
anvi-import-collection -p PROFILE.db -C refined_c10 refined.txt -c T_B_M-contigs.db
anvi-import-collection -p PROFILE.db -C refined_Bin_3 refined_Bin_3.txt -c T_B_M-contigs.db
```
The collection `refined_Bin_3` contains only the bins we extracted from the metabin Bin 3, while the collection `refined_c10` contains all of those bins in addition to the other metabins (that we didn't yet refine).

You can then load up the `refined_c10` collection like this:

```
anvi-interactive -c T_B_M-contigs.db -p PROFILE.db \
    --title "T-B-M co-assembly (CONCOCT_c10 collection)" \
    --collection-autoload refined_c10
```

{% include IMAGE width=40 path="/images/binning-popgen-oral-microbiome/refined_bins_in_concoct_c10.png" caption="The updated CONCOCT_c10 collection in the T-B-M co-assembly." %}

It's a bit messy, but hopefully you can pick out the locations where Bin 3 turned into all those new refined "sub-bins". They are dispersed throughout the co-assembly, intermixed with sequences from the other metabins. This shows again that the automatic binning from CONCOCT, even at a coarse 'metabin' level, is often at odds with the patterns emerging from the current sequence organization based on tetranucleotide frequency and differential coverage.

It is a bit easier to see how fragmented the new, refined bins are in this organization if we load the `refined_Bin_3` collection to see only those 7 bins:

```
anvi-interactive -c T_B_M-contigs.db -p PROFILE.db \
    --title "T-B-M co-assembly (refined bins collection)" \
    --collection-autoload refined_Bin_3
```

{% include IMAGE width=40 path="/images/binning-popgen-oral-microbiome/refined_bins_only.png" caption="The 7 refined bins in the T-B-M co-assembly." %}

You can see that most of the refined bins are broken up into several pieces when organized within this larger set of contigs. It is possible that the metabin 'Bin 3' was missing pieces of these population genomes, and that by adding the sequences that cluster with these bins, we could increase the bins' completeness scores. For instance, we could add the missing sequences between the sections of the _P. salivae_ bin -- though unfortunately doing this would increase only the size of the bin and not its completeness. There are also some sequences that cluster farther away from the rest of their bin -- these could represent potential contaminating sequences that we can now parse out using the additional evidence in this larger figure. For instance, we could remove the split of the TM7 bin that is farther away from the rest -- though unfortunately this would not decrease the redundancy of that bin. In both of these examples, since we don't have changes in the completeness and redundancy estimates to help us track the correctness of our choices, having additional evidence such as gene-level taxonomy or target genome lengths from corresponding reference genomes would be very helpful to justify the additions or removals.

</details>

As you can see, visualizing binning results in different contexts and different organizations can be, paradoxically, both confusing and helpful. We could spend ages trying to improve our binning results, and often only see a marginal improvement. Bin refinement is truly an art rather than an exact science. For the sake of this tutorial, we are done here.

## Population genetics

This section of the tutorial is coming soon.